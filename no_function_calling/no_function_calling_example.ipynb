{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 传统方法：提示词工程 + 正则匹配\n",
    "\n",
    "在 OpenAI Function Calling 出现之前，开发者通常需要依赖精心设计的提示词 (Prompt Engineering) 和正则表达式来从语言模型的输出中提取结构化信息。这种方法不仅繁琐，而且健壮性较差。\n",
    "\n",
    "## 场景：客户信息提取系统\n",
    "\n",
    "假设我们需要从一段用户输入的文本中提取客户的姓名、年龄、邮箱、电话和兴趣爱好。\\\n",
    "\n",
    "### 步骤1：设计提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prompt发送给LLM ---\n",
      "\n",
      "请从以下客户描述中提取结构化信息，并严格按照JSON格式返回：\n",
      "\n",
      "客户描述：我叫张三，今年28岁，邮箱是zhangsan@email.com，电话13812345678，喜欢编程和阅读\n",
      "\n",
      "请返回以下格式的JSON数据：\n",
      "{\n",
      "    \"name\": \"客户姓名\",\n",
      "    \"age\": 年龄数字,\n",
      "    \"email\": \"邮箱地址\",\n",
      "    \"phone\": \"电话号码\",\n",
      "    \"interests\": [\"兴趣1\", \"兴趣2\"]\n",
      "}\n",
      "\n",
      "注意：请确保返回的是有效的JSON格式，不要包含任何其他文字。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 提示词工程示例\n",
    "\n",
    "# 提示词模板，注意JSON结构中的花括号需要双写以避免被format方法误解析为占位符\n",
    "prompt_template = '''\n",
    "请从以下客户描述中提取结构化信息，并严格按照JSON格式返回：\n",
    "\n",
    "客户描述：{user_input}\n",
    "\n",
    "请返回以下格式的JSON数据：\n",
    "{{\n",
    "    \"name\": \"客户姓名\",\n",
    "    \"age\": 年龄数字,\n",
    "    \"email\": \"邮箱地址\",\n",
    "    \"phone\": \"电话号码\",\n",
    "    \"interests\": [\"兴趣1\", \"兴趣2\"]\n",
    "}}\n",
    "\n",
    "注意：请确保返回的是有效的JSON格式，不要包含任何其他文字。\n",
    "'''\n",
    "\n",
    "# 示例输入\n",
    "user_input = \"我叫张三，今年28岁，邮箱是zhangsan@email.com，电话13812345678，喜欢编程和阅读\"\n",
    "\n",
    "# 使用format方法填充用户输入，此时JSON结构中的双花括号会被还原为单花括号\n",
    "formatted_prompt = prompt_template.format(user_input=user_input)\n",
    "print(\"--- Prompt发送给LLM ---\")\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在调用LLM API (使用 requests) ---\n",
      "--- 正在进行非流式调用 ---\n",
      "--- LLM返回的原始JSON ---\n",
      "{\n",
      "  \"id\": \"02174843897810015208d1b4038f629a958d0e327ef7d33d1e1ce\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1748438980,\n",
      "  \"model\": \"deepseek-v3-241226\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"{\\n    \\\"name\\\": \\\"张三\\\",\\n    \\\"age\\\": 28,\\n    \\\"email\\\": \\\"zhangsan@email.com\\\",\\n    \\\"phone\\\": \\\"13812345678\\\",\\n    \\\"interests\\\": [\\\"编程\\\", \\\"阅读\\\"]\\n}\",\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 120,\n",
      "    \"completion_tokens\": 50,\n",
      "    \"total_tokens\": 170,\n",
      "    \"prompt_cache_hit_tokens\": 0,\n",
      "    \"prompt_cache_miss_tokens\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      "--- 提取的回复内容 ---\n",
      "{\n",
      "    \"name\": \"张三\",\n",
      "    \"age\": 28,\n",
      "    \"email\": \"zhangsan@email.com\",\n",
      "    \"phone\": \"13812345678\",\n",
      "    \"interests\": [\"编程\", \"阅读\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests # 导入requests库用于发送HTTP请求\n",
    "import json # 导入json库用于处理JSON数据\n",
    "\n",
    "# https://dashen.zhuanspirit.com/pages/viewpage.action?pageId=512042416\n",
    "\n",
    "# 从环境变量获取API Key，或者直接使用提供的TOKEN\n",
    "# 建议实际应用中使用环境变量，这里为了演示直接使用TOKEN\n",
    "# api_key = os.environ.get(\"DEEPSEEK_API_KEY\", \"YOUR_DEFAULT_TOKEN\") # 更好的实践\n",
    "api_key = \"Mugc9IrDIlud61O0rnytgsHSPuNIyt1h\" # 直接使用大神文档提供的测试 token\n",
    "\n",
    "# 定义API的完整URL\n",
    "# 注意：根据用户提供的POST示例，完整的chat completions接口是 base_url + '/chat/completions'\n",
    "api_url = 'http://gptagent.zhuaninc.com/deepseek/chat/completions'\n",
    "model_name = 'deepseek-chat'\n",
    "\n",
    "base_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"token\": api_key # 使用提供的api_key作为 'token' 头部的值\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": model_name,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "    ],\n",
    "    \"temperature\": 0.0, # 设置温度为0，以获得更稳定的输出\n",
    "}\n",
    "\n",
    "print(\"--- 正在调用LLM API (使用 requests) ---\")\n",
    "\n",
    "try:\n",
    "    # --- 处理非流式响应 (stream=False) ---\n",
    "    # 移除流式传输相关的逻辑，只保留非流式调用\n",
    "    request_headers = base_headers.copy() # 复制基础头部\n",
    "    # 非流式传输需要 Accept: \"application/json\"\n",
    "    request_headers[\"Accept\"] = \"application/json\"\n",
    "    # 确保 payload 中没有 stream=True (虽然在当前逻辑下不会有，但保留更安全)\n",
    "    if \"stream\" in payload:\n",
    "         del payload[\"stream\"]\n",
    "    print(\"--- 正在进行非流式调用 ---\")\n",
    "\n",
    "    # 发送POST请求\n",
    "    response = requests.post(api_url, headers=request_headers, json=payload)\n",
    "    response.raise_for_status() # 检查HTTP响应状态码，如果不是2xx则抛出异常\n",
    "\n",
    "    # 解析JSON响应体\n",
    "    response_data = response.json()\n",
    "\n",
    "    print(\"--- LLM返回的原始JSON ---\")\n",
    "    print(json.dumps(response_data, indent=2, ensure_ascii=False)) # 打印完整的JSON响应\n",
    "\n",
    "    # 提取模型的回复内容\n",
    "    # 假设响应结构类似于OpenAI的非流式格式\n",
    "    if 'choices' in response_data and len(response_data['choices']) > 0:\n",
    "        # 非流式响应的内容在 message 字段中\n",
    "        if 'message' in response_data['choices'][0] and 'content' in response_data['choices'][0]['message']:\n",
    "            ai_response = response_data['choices'][0]['message']['content']\n",
    "            print(\"\\n--- 提取的回复内容 ---\")\n",
    "            print(ai_response)\n",
    "        else:\n",
    "             ai_response = \"无法从响应中提取内容 (message/content 字段缺失)\"\n",
    "             print(f\"\\n警告: {ai_response}\")\n",
    "             print(\"完整的响应数据:\", response_data)\n",
    "    else:\n",
    "        ai_response = \"无法从响应中提取内容 (choices 字段缺失或为空)\"\n",
    "        print(f\"\\n警告: {ai_response}\")\n",
    "        print(\"完整的响应数据:\", response_data)\n",
    "\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    # 捕获requests库可能抛出的异常 (连接错误, HTTP错误等)\n",
    "    print(f\"调用LLM API时发生请求错误: {e}\")\n",
    "    ai_response = \"调用失败\" # 设置一个默认值，防止后续代码出错\n",
    "except Exception as e:\n",
    "    # 捕获其他可能的异常\n",
    "    print(f\"调用LLM API时发生未知错误: {e}\")\n",
    "    ai_response = \"调用失败\" # 设置一个默认值\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
